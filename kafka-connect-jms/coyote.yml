- name: coyote
  title: kafka-connect-jms

- name: Setup Containers
  entries:
    - name: Docker Compose Pull
      command: docker-compose pull
      ignore_exit_code: true
    - name: Docker Compose Build
      command: docker-compose build
    - name: Docker Compose Up
      command: docker-compose up -d
    - name: Sleep a bit
      command: sleep 181
      nolog: true
    - name: Check docker compose log
      command: docker-compose logs
      stdout_has: [ 'INFO success: broker entered RUNNING state' ]
      stdout_not_has: [ 'INFO exited: broker' ]

- name: Setup JMS Sink (ActiveMQ) Connector
  entries:
    - name: Create Kafka Topic
      command: >
        docker run --rm --network=kafkaconnectjms_default landoop/fast-data-dev
          kafka-topics --zookeeper fast-data-dev:2181 --topic jms-sink --partition 1 --replication 1 --create
    - name: Setup a Listener for ActiveMQ Topic
      command: >
        docker exec -d kafkaconnectjms_fast-data-dev_1
          nohup activemq-test -server activemq:61613 -origin /topic/connect_topic -log /var/log/activemq-test.log
    - name: Create a JMS Distributed Connector
      command: >
        docker run --rm --network=kafkaconnectjms_default -i landoop/fast-data-dev
          curl -vs --stderr - -X POST -H "Content-Type: application/json"
               --data @-
               "http://fast-data-dev:8083/connectors"
      stdout_not_has: [ 'HTTP/1.1 [45][0-9][0-9] ' ]
      stdin: |
        {
          "name": "jms-sink",
          "config": {
            "connector.class": "com.datamountaineer.streamreactor.connect.jms.sink.JMSSinkConnector",
            "tasks.max": "1",
            "topics": "jms-sink",
            "connect.jms.url": "tcp://activemq:61616",
            "connect.jms.uri": "tcp://activemq:61616",
            "connect.jms.connection.factory": "ConnectionFactory",
            "connect.jms.initial.context.factory": "org.apache.activemq.jndi.ActiveMQInitialContextFactory",
            "connect.jms.kcql": "INSERT INTO connect_topic SELECT * FROM jms-sink",
            "connect.jms.topics": "connect_topic",
            "connect.deprecated.fields.to.remove": "connect.jms.url"
          }
        }
    - command: sleep 30
      nolog: true

- name: Test JMS Sink Connector
  entries:
    - name: Write Entries into Topic
      command: >
        docker run --rm -i --network=kafkaconnectjms_default landoop/fast-data-dev
          kafka-avro-console-producer --broker-list fast-data-dev:9092
            --topic jms-sink --property schema.registry.url="http://fast-data-dev:8081"
            --property
            value.schema='{"type":"record","name":"User","namespace":"com.datamountaineer.streamreactor.connect.jms","fields":[{"name":"firstName","type":"string"},{"name":"lastName","type":"string"},{"name":"age","type":"int"},{"name":"salary","type":"double"}]}'
      stdin: |
        {"firstName": "John", "lastName": "Smith", "age":30, "salary": 4830}
        {"firstName": "Anna", "lastName": "Jones", "age":28, "salary": 5430}
      timeout: 20s
    - command: sleep 40
      nolog: true
    - name: Read activemq-test logs to verify messages were passed
      command: >
        docker exec kafkaconnectjms_fast-data-dev_1 cat /var/log/activemq-test.log
      stdout_has: [ 'John', 'Smith', 'Anna', 'Jones' ]

- name: Setup JMS (ActiveMQ) Source Connector
  entries:
    - name: Create Kafka Topic
      command: >
        docker run --rm --network=kafkaconnectjms_default landoop/fast-data-dev
          kafka-topics --zookeeper fast-data-dev:2181 --topic jms-source --partition 1 --replication 1 --create
    - name: Kill sink test listener so our connector can attacht to the topic
      command: >
        docker exec -d kafkaconnectjms_fast-data-dev_1 killall activemq-test
    - name: Create a JMS Distributed Connector
      command: >
        docker run --rm --network=kafkaconnectjms_default -i landoop/fast-data-dev
          curl -vs --stderr - -X POST -H "Content-Type: application/json"
               --data @-
               "http://fast-data-dev:8083/connectors"
      stdout_not_has: [ 'HTTP/1.1 [45][0-9][0-9] ' ]
      stdin: |
        {
          "name": "jms-source",
          "config": {
            "connector.class": "com.datamountaineer.streamreactor.connect.jms.source.JMSSourceConnector",
            "tasks.max": "1",
            "connect.jms.url": "tcp://activemq:61616",
            "connect.jms.connection.factory": "ConnectionFactory",
            "connect.jms.initial.context.factory": "org.apache.activemq.jndi.ActiveMQInitialContextFactory",
            "connect.jms.kcql": "INSERT INTO jms-source SELECT * FROM connect_topic",
            "connect.jms.topics": "connect_topic"
          }
        }
    - command: sleep 30
      nolog: true

- name: Test JMS Source Connector
  entries:
    - name: Write Entries into Topic
      command: >
        docker run --rm -i --network=kafkaconnectjms_default landoop/fast-data-dev
          kafka-avro-console-producer --broker-list fast-data-dev:9092
            --topic jms-sink --property schema.registry.url="http://fast-data-dev:8081"
            --property
            value.schema='{"type":"record","name":"User","namespace":"com.datamountaineer.streamreactor.connect.jms","fields":[{"name":"firstName","type":"string"},{"name":"lastName","type":"string"},{"name":"age","type":"int"},{"name":"salary","type":"double"}]}'
      stdin: |
        {"firstName": "John", "lastName": "Smith", "age":30, "salary": 4830}
        {"firstName": "Anna", "lastName": "Jones", "age":28, "salary": 5430}
      timeout: 20s
    - command: sleep 40
      nolog: true
    - name: Read Entries from Topic
      command: >
        timeout 20
        docker run --rm --network=kafkaconnectjms_default landoop/fast-data-dev
          kafka-avro-console-consumer --bootstrap-server fast-data-dev:9092
                                      --topic jms-source --from-beginning --new-consumer
                                      --property schema.registry.url=http://fast-data-dev:8081
      ignore_exit_code: true
      stdout_has: [ 'John', 'Smith', 'Anna', 'Jones' ]

- name: Other tests
  entries:
    - name: Read First 6000 Lines of Connect Logs
      command: >
        docker exec kafkaconnectjms_fast-data-dev_1 head -n6000 /var/log/connect-distributed.log
      stdout_not_has: [ '\] ERROR' ]

- name: Clean-up Containers
  entries:
    - name: Docker Compose Down
      command: docker-compose down
