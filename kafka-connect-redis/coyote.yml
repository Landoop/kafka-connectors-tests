- name: coyote
  title: kafka-connect-redis

- name: Setup Containers
  entries:
    - name: Docker Compose Pull
      command: docker-compose pull
      ignore_exit_code: true
    - name: Docker Compose Up
      command: docker-compose up -d
    - name: Sleep a bit
      command: sleep 221
      nolog: true
    - name: Check docker compose log
      command: docker-compose logs
      stdout_has: [ 'INFO success: broker entered RUNNING state' ]
      stdout_not_has: [ 'INFO exited: broker' ]

- name: Setup Redis Connector
  entries:
    - name: Create Topic
      command: >
        docker run --rm --network=kafkaconnectredis_default landoop/fast-data-dev
          kafka-topics --zookeeper fast-data-dev:2181 --topic person_redis --partitions 1 --replication-factor 1 --create
    - name: Create a Redis Distributed Connector
      command: >
        docker run --rm --network=kafkaconnectredis_default -i landoop/fast-data-dev
          curl -vs --stderr - -X POST -H "Content-Type: application/json"
               --data @-
               "http://fast-data-dev:8083/connectors"
      stdout_not_has: [ 'HTTP/1.1 [45][0-9][0-9] ' ]
      stdin: |
        {
          "name": "redis-%UNIQUE_RC%",
          "config": {
            "connector.class": "com.datamountaineer.streamreactor.connect.redis.sink.RedisSinkConnector",
            "tasks.max": "1",
            "topics": "person_redis",
            "connect.redis.connection.host": "redis",
            "connect.redis.host": "redis",
            "connect.redis.connection.port": "6379",
            "connect.redis.port": "6379",
            "connect.redis.connection.password": "pass",
            "connect.redis.password": "pass",
            "connect.redis.sink.kcql": "SELECT firstName, lastName, salary from person_redis PK lastName",
            "connect.redis.kcql": "SELECT firstName, lastName, salary from person_redis PK lastName",
            "connect.deprecated.fields.to.remove": "connect.redis.sink.kcql, connect.redis.connection.host, connect.redis.connection.port, connect.redis.connection.password"
          }
        }
    - command: sleep 30
      nolog: true

- name: Test Connector
  entries:
    - name: Write Entries into Topic
      command: >
        docker run --rm -i --network=kafkaconnectredis_default landoop/fast-data-dev
          kafka-avro-console-producer --broker-list fast-data-dev:9092
            --topic person_redis --property schema.registry.url="http://fast-data-dev:8081"
            --property
            value.schema='{"type":"record","name":"User","namespace":"com.datamountaineer.streamreactor.connect.redis","fields":[{"name":"firstName","type":"string"},{"name":"lastName","type":"string"},{"name":"age","type":"int"},{"name":"salary","type":"double"}]}'
      stdin: |
        {"firstName": "%UNIQUE_NAME1%", "lastName": "%UNIQUE_NAME2%", "age":30, "salary": 4830}
        {"firstName": "%UNIQUE_NAME3%", "lastName": "%UNIQUE_NAME4%", "age":30, "salary": 3048}
      timeout: 20s
    - command: sleep 60
      nolog: true
    - name: Verify entry 1
      command:  docker run --rm --network=kafkaconnectredis_default redis redis-cli -h redis -a pass get "%UNIQUE_NAME2%"
      stdout_has: [ '%UNIQUE_NAME1%', '%UNIQUE_NAME2%', '4830' ]
    - name: Verify entry 2
      command:  docker run --rm --network=kafkaconnectredis_default redis redis-cli -h redis -a pass get "%UNIQUE_NAME4%"
      stdout_has: [ '%UNIQUE_NAME3%', '%UNIQUE_NAME4%', '3048' ]
    - name: Read First 4000 Lines of Connect Logs
      command: >
        docker exec kafkaconnectredis_fast-data-dev_1 head -n4000 /var/log/connect-distributed.log
      stdout_not_has: [ '\] ERROR' ]

- name: Clean-up Containers
  entries:
    - name: Docker Compose Down
      command: docker-compose down
