- name: coyote
  title: kafka-connect-mqtt

- name: Setup Containers
  entries:
    - name: Docker Compose Pull
      command: docker-compose -p kafkaconnectmqtt pull
      ignore_exit_code: true
    - name: Docker Compose Build
      command: docker-compose -p kafkaconnectmqtt build
    - name: Docker Compose Up
      command: docker-compose -p kafkaconnectmqtt up -d
    - name: Wait for Connect to get up
      command: >
        bash -c '
          for ((i=0;i<30;i++)); do
            sleep 10;
            docker exec kafkaconnectmqtt_fast-data-dev_1 curl "http://localhost:8083/connectors" && break;
          done'
      nolog: true
    - name: Check docker compose log
      command: docker-compose -p kafkaconnectmqtt logs
      stdout_has: [ 'INFO success: broker entered RUNNING state' ]
      stdout_not_has: [ 'INFO exited: broker' ]
    - name: fast-data-dev build.info
      command: docker exec kafkaconnectmqtt_fast-data-dev_1 cat /build.info

- name: Setup MQTT (ActiveMQ) Connector
  entries:
    - name: Create Kafka Topic
      command: >
        docker run --rm --network=kafkaconnectmqtt_default landoop/fast-data-dev
          kafka-topics --zookeeper fast-data-dev:2181 --topic mqtt-source --partitions 1 --replication-factor 1 --create
    - name: Setup a Listener for ActiveMQ Topic
      command: >
        docker exec -d kafkaconnectmqtt_fast-data-dev_1
          nohup activemq-test -server activemq:1883 -origin /topic/connect_topic -log /var/log/activemq-test.log
    - name: Create a MQTT Distributed Connector
      command: >
        docker exec -i kafkaconnectmqtt_fast-data-dev_1
          curl -vs --stderr - -X POST -H "Content-Type: application/json"
               --data @-
               "http://fast-data-dev:8083/connectors"
      stdout_not_has: [ 'HTTP/1.1 [45][0-9][0-9] ' ]
      stdin: |
        {
          "name": "mqtt-source",
          "config": {
            "connector.class": "com.datamountaineer.streamreactor.connect.mqtt.source.MqttSourceConnector",
            "tasks.max": "1",
            "connect.mqtt.connection.clean": "true",
            "connect.mqtt.connection.timeout": "1000",
            "connect.mqtt.kcql": "INSERT INTO mqtt-source SELECT * FROM /topic/connect_topic WITHCONVERTER=`com.datamountaineer.streamreactor.connect.converters.source.AvroConverter`",
            "connect.mqtt.connection.keep.alive": "1000",
            "connect.source.converter.avro.schemas": "/topic/connect_topic=/schema.avro",
            "connect.mqtt.client.id": "dm_source_id,",
            "connect.mqtt.converter.throw.on.error": "true",
            "connect.mqtt.hosts": "tcp://activemq:1883",
            "connect.mqtt.service.quality": "1"
          }
        }
    - command: sleep 15
      nolog: true

- name: Test Connector
  entries:
    - name: Read Entries from Topic
      command: >
        timeout 10
        docker exec kafkaconnectmqtt_fast-data-dev_1
          kafka-avro-console-consumer --bootstrap-server fast-data-dev:9092
                                      --topic mqtt-source --from-beginning
                                      --property schema.registry.url=http://fast-data-dev:8081
      ignore_exit_code: true
      stdout_has: [ '{"output":5,"deviceid":"plant1-room3-pod4"}', '{"output":16,"deviceid":"ship5-deck2-rack3"}' ]
    - name: Read activemq-test logs to verify messages were passed
      command: >
        docker exec kafkaconnectmqtt_fast-data-dev_1 cat /var/log/activemq-test.log
      stdout_has: [ 'plant1-room3-pod4', 'ship5-deck2-rack3' ]
    - name: Read First 7000 Lines of Connect Logs
      command: >
        docker exec kafkaconnectmqtt_fast-data-dev_1 head -n7000 /var/log/connect-distributed.log
      stdout_not_has: [ '\] ERROR' ]

- name: Clean-up Containers
  entries:
    - name: Docker Compose Down
      command: docker-compose -p kafkaconnectmqtt down
